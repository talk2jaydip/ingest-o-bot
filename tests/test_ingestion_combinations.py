"""Test actual document ingestion with different vector store and embeddings combinations.

This script tests real end-to-end ingestion with:
1. ChromaDB + Hugging Face (fully offline)
2. ChromaDB + Azure OpenAI (if credentials available)
3. Azure Search + Cohere (if credentials available)
4. Azure Search + Hugging Face (if credentials available)
"""

import asyncio
import os
import sys
import tempfile
import shutil
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from ingestor.config import (
    PipelineConfig,
    VectorStoreMode,
    EmbeddingsMode,
    ChromaDBConfig,
    HuggingFaceEmbeddingsConfig,
    SearchConfig,
    AzureOpenAIConfig,
    CohereEmbeddingsConfig,
    InputConfig,
    ArtifactsConfig,
    ChunkingConfig,
    PerformanceConfig,
    LoggingConfig,
    DocumentIntelligenceConfig,
    OfficeExtractorConfig,
    OfficeExtractorMode,
    AzureCredentials,
    KeyVaultConfig,
    MediaDescriberMode,
    TableRenderMode,
)
from ingestor.pipeline import Pipeline
from ingestor.vector_store import create_vector_store
from ingestor.embeddings_provider import create_embeddings_provider


def test_chromadb_huggingface_available():
    """Check if ChromaDB and Hugging Face dependencies are available."""
    try:
        import chromadb
        import sentence_transformers
        return True
    except ImportError:
        return False


def test_cohere_available():
    """Check if Cohere is available."""
    try:
        import cohere
        return True
    except ImportError:
        return False


async def test_offline_chromadb_huggingface():
    """Test fully offline ingestion with ChromaDB + Hugging Face.

    This test should work without any API keys or cloud services.
    """
    print("\n" + "="*80)
    print("TEST 1: ChromaDB + Hugging Face (Fully Offline)")
    print("="*80)

    if not test_chromadb_huggingface_available():
        print("‚è≠Ô∏è  SKIPPED: ChromaDB or sentence-transformers not installed")
        print("   Install with: pip install -r requirements-chromadb.txt requirements-embeddings.txt")
        return False

    # Create temporary directories
    temp_dir = tempfile.mkdtemp(prefix="test_chroma_")
    chroma_dir = os.path.join(temp_dir, "chroma_db")
    artifacts_dir = os.path.join(temp_dir, "artifacts")

    try:
        print(f"\nüìÅ Test directories:")
        print(f"   ChromaDB: {chroma_dir}")
        print(f"   Artifacts: {artifacts_dir}")

        # Set environment variables for this test
        os.environ.update({
            # Vector Store: ChromaDB
            'VECTOR_STORE_MODE': 'chromadb',
            'CHROMADB_COLLECTION_NAME': 'test-offline',
            'CHROMADB_PERSIST_DIR': chroma_dir,

            # Embeddings: Hugging Face
            'EMBEDDINGS_MODE': 'huggingface',
            'HUGGINGFACE_MODEL_NAME': 'sentence-transformers/all-MiniLM-L6-v2',
            'HUGGINGFACE_DEVICE': 'cpu',
            'HUGGINGFACE_BATCH_SIZE': '16',

            # Input/Output
            'INPUT_MODE': 'local',
            'LOCAL_INPUT_GLOB': 'data/Mixed_6pages.pdf',
            'ARTIFACTS_MODE': 'local',
            'LOCAL_ARTIFACTS_DIR': artifacts_dir,

            # Processing
            'AZURE_OFFICE_EXTRACTOR_MODE': 'markitdown',
            'AZURE_MEDIA_DESCRIBER': 'disabled',
            'AZURE_USE_INTEGRATED_VECTORIZATION': 'false',

            # Chunking
            'AZURE_CHUNKING_MAX_CHARS': '1000',
            'AZURE_CHUNKING_MAX_TOKENS': '250',
            'AZURE_CHUNKING_OVERLAP_PERCENT': '10',
            'AZURE_CHUNKING_MAX_WORKERS': '2',

            # Minimal Azure config (required even for offline mode - need to fix this)
            'AZURE_SEARCH_SERVICE': 'dummy',
            'AZURE_SEARCH_INDEX': 'dummy',
            'AZURE_SEARCH_KEY': 'dummy',
            'AZURE_STORAGE_ACCOUNT': 'dummy',
            'AZURE_STORAGE_ACCOUNT_KEY': 'dummy',
            'AZURE_DOC_INT_ENDPOINT': 'https://dummy.cognitiveservices.azure.com/',
            'AZURE_DOC_INT_KEY': 'dummy',
            'AZURE_OPENAI_ENDPOINT': 'https://dummy.openai.azure.com/',
            'AZURE_OPENAI_KEY': 'dummy',
            'AZURE_OPENAI_CHAT_DEPLOYMENT': 'dummy',
            'AZURE_OPENAI_EMBEDDING_DEPLOYMENT': 'dummy',
        })

        # Load config from environment
        config = PipelineConfig.from_env()

        print("\nüîß Configuration:")
        print(f"   Vector Store: {config.vector_store_mode}")
        print(f"   Embeddings: {config.embeddings_mode}")
        print(f"   Model: {config.embeddings_config.model_name}")
        print(f"   Input: {config.input.local_glob if hasattr(config.input, 'local_glob') else 'N/A'}")

        # Create pipeline
        print("\n‚öôÔ∏è  Initializing pipeline...")
        pipeline = Pipeline(config)
        await pipeline._initialize_components()

        # Verify components were created
        assert pipeline.embeddings_provider is not None, "Embeddings provider not initialized"
        assert pipeline.vector_store is not None, "Vector store not initialized"

        print(f"   ‚úÖ Embeddings Provider: {type(pipeline.embeddings_provider).__name__}")
        print(f"   ‚úÖ Vector Store: {type(pipeline.vector_store).__name__}")
        print(f"   ‚úÖ Embedding Dimensions: {pipeline.embeddings_provider.get_dimensions()}")

        # Test embedding generation
        print("\nüß™ Testing embedding generation...")
        test_text = "This is a test sentence for embedding generation."
        embedding = await pipeline.embeddings_provider.generate_embedding(test_text)

        assert embedding is not None, "Embedding generation failed"
        assert len(embedding) == 384, f"Expected 384 dimensions, got {len(embedding)}"
        print(f"   ‚úÖ Generated embedding with {len(embedding)} dimensions")

        # Test batch embedding
        test_texts = ["First test sentence.", "Second test sentence.", "Third test sentence."]
        embeddings = await pipeline.embeddings_provider.generate_embeddings_batch(test_texts)

        assert len(embeddings) == 3, f"Expected 3 embeddings, got {len(embeddings)}"
        print(f"   ‚úÖ Generated {len(embeddings)} embeddings in batch")

        # Run full pipeline on a test file
        print("\nüìÑ Running full pipeline ingestion...")

        # Check if test file exists
        test_file = "data/Mixed_6pages.pdf"
        if not os.path.exists(test_file):
            print(f"   ‚ö†Ô∏è  Test file not found: {test_file}")
            print(f"   Creating a simple test file instead...")

            # Create a simple text file for testing
            test_file = os.path.join(temp_dir, "test_document.txt")
            with open(test_file, "w", encoding="utf-8") as f:
                f.write("This is a test document for ChromaDB and Hugging Face integration.\n\n")
                f.write("It contains multiple paragraphs to create multiple chunks.\n\n")
                f.write("The pluggable architecture supports various vector stores and embeddings providers.\n\n")
                f.write("This test verifies that ChromaDB works correctly with local Hugging Face embeddings.\n")

            # Update environment to point to test file
            os.environ['LOCAL_INPUT_GLOB'] = test_file
            config = PipelineConfig.from_env()
            pipeline = Pipeline(config)
            await pipeline._initialize_components()

        # Run the full pipeline
        print(f"   Processing file: {test_file}")
        stats = await pipeline.run()

        print(f"   ‚úÖ Pipeline completed successfully!")
        print(f"   ‚úÖ Documents processed: {stats.successful_documents}/{stats.total_documents}")
        print(f"   ‚úÖ Chunks uploaded: {stats.total_chunks_indexed}")
        print(f"   ‚úÖ ChromaDB data stored at: {chroma_dir}")

        print("\n" + "="*80)
        print("‚úÖ TEST 1 PASSED: ChromaDB + Hugging Face works!")
        print("="*80)
        return True

    except Exception as e:
        print("\n" + "="*80)
        print(f"‚ùå TEST 1 FAILED: {str(e)}")
        print("="*80)
        import traceback
        traceback.print_exc()
        return False

    finally:
        # Cleanup
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                print(f"\nüßπ Cleaned up test directory: {temp_dir}")
        except Exception as e:
            print(f"\n‚ö†Ô∏è  Could not cleanup {temp_dir}: {e}")


async def test_chromadb_azure_openai():
    """Test ChromaDB + Azure OpenAI (requires Azure credentials)."""
    print("\n" + "="*80)
    print("TEST 2: ChromaDB + Azure OpenAI")
    print("="*80)

    # Check if Azure OpenAI credentials are available
    if not os.getenv("AZURE_OPENAI_ENDPOINT") or not os.getenv("AZURE_OPENAI_KEY"):
        print("‚è≠Ô∏è  SKIPPED: Azure OpenAI credentials not available")
        print("   Set AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_KEY to run this test")
        return None

    if not test_chromadb_huggingface_available():
        print("‚è≠Ô∏è  SKIPPED: ChromaDB not installed")
        return None

    print("üîß Would test ChromaDB + Azure OpenAI here...")
    print("   (Implementation similar to test 1 but with Azure OpenAI embeddings)")
    return None


async def test_azure_search_cohere():
    """Test Azure Search + Cohere (requires Azure and Cohere credentials)."""
    print("\n" + "="*80)
    print("TEST 3: Azure Search + Cohere")
    print("="*80)

    # Check credentials
    has_azure = os.getenv("AZURE_SEARCH_ENDPOINT") or os.getenv("AZURE_SEARCH_SERVICE")
    has_cohere = os.getenv("COHERE_API_KEY")

    if not has_azure:
        print("‚è≠Ô∏è  SKIPPED: Azure Search credentials not available")
        return None

    if not has_cohere:
        print("‚è≠Ô∏è  SKIPPED: Cohere API key not available")
        return None

    if not test_cohere_available():
        print("‚è≠Ô∏è  SKIPPED: Cohere library not installed")
        print("   Install with: pip install cohere")
        return None

    print("üîß Would test Azure Search + Cohere here...")
    return None


async def test_azure_search_huggingface():
    """Test Azure Search + Hugging Face (hybrid cloud/local)."""
    print("\n" + "="*80)
    print("TEST 4: Azure Search + Hugging Face (Hybrid)")
    print("="*80)

    has_azure = os.getenv("AZURE_SEARCH_ENDPOINT") or os.getenv("AZURE_SEARCH_SERVICE")

    if not has_azure:
        print("‚è≠Ô∏è  SKIPPED: Azure Search credentials not available")
        return None

    if not test_chromadb_huggingface_available():
        print("‚è≠Ô∏è  SKIPPED: Hugging Face dependencies not installed")
        return None

    print("üîß Would test Azure Search + Hugging Face here...")
    return None


async def main():
    """Run all ingestion tests."""
    print("\n" + "="*80)
    print("PLUGGABLE ARCHITECTURE - INGESTION TESTS")
    print("="*80)
    print("\nTesting actual document ingestion with different combinations...")

    results = []

    # Test 1: Fully offline (most important - should always work)
    result1 = await test_offline_chromadb_huggingface()
    results.append(("ChromaDB + Hugging Face (Offline)", result1))

    # Test 2: ChromaDB + Azure OpenAI (if credentials available)
    result2 = await test_chromadb_azure_openai()
    if result2 is not None:
        results.append(("ChromaDB + Azure OpenAI", result2))

    # Test 3: Azure Search + Cohere (if credentials available)
    result3 = await test_azure_search_cohere()
    if result3 is not None:
        results.append(("Azure Search + Cohere", result3))

    # Test 4: Azure Search + Hugging Face (if credentials available)
    result4 = await test_azure_search_huggingface()
    if result4 is not None:
        results.append(("Azure Search + Hugging Face", result4))

    # Print summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)

    passed = [name for name, result in results if result is True]
    failed = [name for name, result in results if result is False]
    skipped = 4 - len(results)

    print(f"\n‚úÖ Passed: {len(passed)}")
    for name in passed:
        print(f"   - {name}")

    if failed:
        print(f"\n‚ùå Failed: {len(failed)}")
        for name in failed:
            print(f"   - {name}")

    if skipped > 0:
        print(f"\n‚è≠Ô∏è  Skipped: {skipped} (missing dependencies or credentials)")

    print("\n" + "="*80)

    if failed:
        print("‚ùå SOME TESTS FAILED")
        sys.exit(1)
    elif passed:
        print("‚úÖ ALL RUNNABLE TESTS PASSED")
        sys.exit(0)
    else:
        print("‚ö†Ô∏è  NO TESTS COULD BE RUN (install dependencies)")
        sys.exit(0)


if __name__ == "__main__":
    asyncio.run(main())
