# ==========================================
# ChromaDB + Hugging Face - FULLY OFFLINE SETUP
# ==========================================
#
# This configuration enables completely offline document processing
# with no cloud dependencies or API costs.
#
# SETUP:
# ☐ 1. Install dependencies: pip install -r requirements-chromadb.txt
# ☐ 2. Install embeddings: pip install -r requirements-embeddings.txt
# ☐ 3. Copy this file to .env
# ☐ 4. Place PDF files in ./documents/ directory
# ☐ 5. Run: python examples/offline_chromadb_huggingface.py
#
# FEATURES:
# ✅ Fully offline - no internet required (after initial model download)
# ✅ Zero API costs
# ✅ Complete data privacy
# ✅ Local vector storage with persistence
# ✅ Multilingual model support
# ==========================================

# ==========================================
# Vector Store: ChromaDB (Persistent Local Storage)
# ==========================================
VECTOR_STORE_MODE=chromadb
CHROMADB_COLLECTION_NAME=offline-documents
CHROMADB_PERSIST_DIR=./chroma_db
CHROMADB_BATCH_SIZE=1000

# Alternative: In-memory mode (data lost on exit)
# CHROMADB_COLLECTION_NAME=temp-documents
# # No CHROMADB_PERSIST_DIR = in-memory

# Alternative: Client/Server mode
# CHROMADB_HOST=localhost
# CHROMADB_PORT=8000
# CHROMADB_AUTH_TOKEN=secret-token

# ==========================================
# Embeddings: Hugging Face (Local Models)
# ==========================================
EMBEDDINGS_MODE=huggingface

# Model Options (choose one):
# Quality English (768 dims, ~420MB) - Default
HUGGINGFACE_MODEL_NAME=sentence-transformers/all-mpnet-base-v2

# Fast & lightweight (384 dims, ~90MB)
# HUGGINGFACE_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2

# Multilingual quality (768 dims, ~1GB)
# HUGGINGFACE_MODEL_NAME=sentence-transformers/paraphrase-multilingual-mpnet-base-v2

# SOTA Multilingual (1024 dims, ~2.2GB)
# HUGGINGFACE_MODEL_NAME=intfloat/multilingual-e5-large

# SOTA English (1024 dims, ~1.3GB)
# HUGGINGFACE_MODEL_NAME=BAAI/bge-large-en-v1.5

# Device configuration
HUGGINGFACE_DEVICE=cpu  # or cuda (NVIDIA GPU), mps (Apple Silicon)
HUGGINGFACE_BATCH_SIZE=32
HUGGINGFACE_NORMALIZE=true

# ==========================================
# Input: Local Files
# ==========================================
INPUT_MODE=local
LOCAL_INPUT_GLOB=./documents/**/*.pdf

# ==========================================
# Artifacts: Local Storage
# ==========================================
ARTIFACTS_MODE=local
LOCAL_ARTIFACTS_DIR=./artifacts

# ==========================================
# Document Processing: Offline Mode
# ==========================================
AZURE_OFFICE_EXTRACTOR_MODE=markitdown

# ==========================================
# Chunking Settings (Dynamic Adjustment)
# ==========================================
# The pipeline automatically adjusts chunking limits based on the
# embedding model's max_seq_length to prevent truncation.
#
# For all-mpnet-base-v2 (max_seq_length = 384):
#   Safe limit = 384 * (1 - 0.15 - 0.10) = 288 tokens
#   (15% safety buffer + 10% overlap allowance)
#
# Generic parameter names (recommended):
CHUNKING_MAX_CHARS=2000
CHUNKING_MAX_TOKENS=500
CHUNKING_OVERLAP_PERCENT=10
CHUNKING_CROSS_PAGE_OVERLAP=false

# Azure-prefixed names also work (backward compatibility):
# AZURE_CHUNKING_MAX_CHARS=2000
# AZURE_CHUNKING_MAX_TOKENS=500
# AZURE_CHUNKING_OVERLAP_PERCENT=10
# AZURE_CHUNKING_CROSS_PAGE_OVERLAP=false

# Optional: Manually set max_seq_length if model doesn't report it
# EMBEDDINGS_MAX_SEQ_LENGTH=256

# ==========================================
# Media Description: Disabled (offline mode)
# ==========================================
AZURE_MEDIA_DESCRIBER=disabled

# ==========================================
# Table Rendering
# ==========================================
AZURE_TABLE_RENDER=markdown
AZURE_TABLE_SUMMARIES=false

# ==========================================
# Performance Settings
# ==========================================
AZURE_CHUNKING_MAX_WORKERS=4
AZURE_CHUNKING_MAX_IMAGE_CONCURRENCY=8
AZURE_CHUNKING_MAX_BATCH_UPLOAD_CONCURRENCY=5

# ==========================================
# Logging
# ==========================================
LOG_LEVEL=INFO
LOG_FILE_LEVEL=DEBUG
LOG_ARTIFACTS=true
LOG_USE_COLORS=true

# ==========================================
# NOTES:
# - First run will download Hugging Face model (~90MB-2GB depending on model)
# - Models are cached in ~/.cache/huggingface/ for future runs
# - ChromaDB data stored in ./chroma_db/
# - No Azure services required!
# - Dynamic chunking automatically adjusts limits based on model capacity
# - You'll see warning messages if chunking limits are reduced
# ==========================================
