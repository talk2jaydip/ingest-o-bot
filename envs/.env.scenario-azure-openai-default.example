# ============================================================================
# SCENARIO: Azure Full Stack (Default/Production Configuration)
# ============================================================================
#
# DESCRIPTION:
# Complete Azure-based solution using Azure AI Search, Azure OpenAI embeddings,
# Azure Document Intelligence for PDF processing, and Azure Blob Storage.
# This is the classic enterprise configuration with all Azure services.
#
# USE CASE:
# - Production enterprise deployments
# - Teams already using Azure infrastructure
# - Need for Azure SLA and enterprise support
# - Compliance requirements (data stays in Azure region)
# - Integrated vectorization for simplified architecture
#
# COST ESTIMATE (monthly):
# - Azure Search: $250-500 (Standard tier)
# - Azure OpenAI: $100-300 (embeddings + GPT-4 descriptions)
# - Document Intelligence: $10-100 (per 1K pages)
# - Blob Storage: $20-50 (100GB-1TB)
# TOTAL: ~$380-950/month
#
# REQUIREMENTS:
# - Azure subscription
# - Azure AI Search service
# - Azure OpenAI service with embeddings deployment
# - Azure Document Intelligence service
# - Azure Storage account
# - Blob containers created
#
# ============================================================================

# ============================================================================
# VECTOR STORE: Azure AI Search
# ============================================================================
VECTOR_STORE_MODE=azure_search
AZURE_SEARCH_SERVICE=your-search-service
AZURE_SEARCH_KEY=your-search-admin-key-here
AZURE_SEARCH_INDEX=production-documents

# Alternative: Use full endpoint URL
# AZURE_SEARCH_ENDPOINT=https://your-search-service.search.windows.net

# ============================================================================
# EMBEDDINGS: Azure OpenAI
# ============================================================================
EMBEDDINGS_MODE=azure_openai  # Optional: auto-detected

AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
AZURE_OPENAI_KEY=your-openai-api-key-here
AZURE_OPENAI_API_VERSION=2024-12-01-preview

# Embedding Model Configuration:
# ----------------------------------------------------------------------------
# Option 1: text-embedding-ada-002 (default, most compatible)
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-ada-002
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
# Fixed 1536 dimensions, 8191 max tokens

# Option 2: text-embedding-3-small (newer, customizable dimensions)
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-small
# AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# AZURE_OPENAI_EMBEDDING_DIMENSIONS=1536  # 512-1536 range

# Option 3: text-embedding-3-large (best quality, highest cost)
# AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-large
# AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-large
# AZURE_OPENAI_EMBEDDING_DIMENSIONS=3072  # 256-3072 range

# Chat Model (for image descriptions):
AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini
AZURE_OPENAI_MODEL_NAME=gpt-4o-mini

# Concurrency & Performance:
AZURE_OPENAI_MAX_CONCURRENCY=5
AZURE_OPENAI_MAX_RETRIES=3
AZURE_OPENAI_TIMEOUT=30

# ============================================================================
# DOCUMENT INTELLIGENCE: Azure DI
# ============================================================================
AZURE_DOC_INT_ENDPOINT=https://your-docint.cognitiveservices.azure.com/
AZURE_DOC_INT_KEY=your-document-intelligence-key-here
AZURE_DI_MAX_CONCURRENCY=3

# Office Document Processing:
AZURE_OFFICE_EXTRACTOR_MODE=hybrid  # Try Azure DI, fallback to MarkItDown
AZURE_OFFICE_OFFLINE_FALLBACK=true  # Enable fallback
AZURE_OFFICE_MAX_FILE_SIZE_MB=100

# ============================================================================
# STORAGE: Azure Blob Storage
# ============================================================================
AZURE_STORAGE_ACCOUNT=your-storage-account
AZURE_STORAGE_ACCOUNT_KEY=your-storage-account-key-here

# Alternative: Connection string
# AZURE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=...;AccountKey=...

# Alternative: SAS token
# AZURE_STORAGE_SAS_TOKEN=sv=2023-01-03&st=2024-01-01...

# ============================================================================
# INPUT: Azure Blob Storage
# ============================================================================
AZURE_INPUT_MODE=blob
AZURE_STORAGE_CONTAINER=production-documents

# Simple container naming (auto-generates all container names):
# - production-documents-input (input docs - YOU create this)
# - production-documents-pages (auto-created)
# - production-documents-chunks (auto-created)
# - production-documents-images (auto-created)
# - production-documents-citations (auto-created)

# Alternative: Explicit container names
# AZURE_BLOB_CONTAINER_IN=my-input-container
# AZURE_BLOB_PREFIX=2024/january/  # Optional: folder filter

# ============================================================================
# ARTIFACTS: Azure Blob Storage
# ============================================================================
AZURE_ARTIFACTS_MODE=blob
AZURE_BLOB_CONTAINER_PREFIX=production-documents

# Explicit output containers (auto-created by pipeline):
AZURE_BLOB_CONTAINER_OUT_PAGES=pages
AZURE_BLOB_CONTAINER_OUT_CHUNKS=chunks
AZURE_BLOB_CONTAINER_OUT_IMAGES=images
AZURE_BLOB_CONTAINER_CITATIONS=citations  # Optional: per-page PDFs

# Force local artifacts (overrides blob mode):
# AZURE_ARTIFACTS_DIR=./artifacts  # Uncomment to store locally instead

# ============================================================================
# PROCESSING OPTIONS
# ============================================================================

# Integrated Vectorization:
# ----------------------------------------------------------------------------
# Option A: Client-side embeddings (default, more control)
AZURE_USE_INTEGRATED_VECTORIZATION=false

# Option B: Server-side embeddings (simpler, Azure Search handles embeddings)
# AZURE_USE_INTEGRATED_VECTORIZATION=true
# Note: Requires Azure Search integrated vectorization configured

# Media Description:
# ----------------------------------------------------------------------------
AZURE_MEDIA_DESCRIBER=gpt4o  # AI-powered image descriptions

# Alternative options:
# AZURE_MEDIA_DESCRIBER=disabled  # No image descriptions
# AZURE_MEDIA_DESCRIBER=content_understanding  # Use Content Understanding API

# Table Rendering:
# ----------------------------------------------------------------------------
AZURE_TABLE_RENDER=html  # Options: html, markdown, plain
AZURE_TABLE_SUMMARIES=false  # LLM-generated table summaries (costs extra)

# Page Citations:
# ----------------------------------------------------------------------------
AZURE_GENERATE_PAGE_PDFS=false  # Generate per-page PDFs for citations

# ============================================================================
# CHUNKING CONFIGURATION (Dynamic Adjustment)
# ============================================================================
# For text-embedding-ada-002 (8191 max tokens):
#   Your configured limits are well within capacity
CHUNKING_MAX_TOKENS=1000  # Maximum tokens per chunk
CHUNKING_MAX_CHARS=5000  # Maximum characters per chunk (soft limit)
CHUNKING_OVERLAP_PERCENT=10  # 10% overlap between chunks

# Alternative: Azure-prefixed names (backward compatibility)
AZURE_CHUNKING_MAX_TOKENS=1000
AZURE_CHUNKING_MAX_CHARS=5000
AZURE_CHUNKING_OVERLAP_PERCENT=10
AZURE_CHUNKING_CROSS_PAGE_OVERLAP=false

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================
AZURE_CHUNKING_MAX_WORKERS=4  # Parallel document processing
AZURE_CHUNKING_MAX_IMAGE_CONCURRENCY=8  # Image processing concurrency
AZURE_CHUNKING_MAX_BATCH_UPLOAD_CONCURRENCY=5  # Batch upload concurrency
AZURE_EMBED_BATCH_SIZE=128  # Embeddings batch size
AZURE_UPLOAD_BATCH_SIZE=1000  # Search index upload batch size
AZURE_UPLOAD_DELAY=0.5  # Delay between uploads (seconds)

# ============================================================================
# DOCUMENT ACTIONS
# ============================================================================
AZURE_DOCUMENT_ACTION=add  # Options: add, remove, removeall

# ============================================================================
# LOGGING
# ============================================================================
LOG_LEVEL=INFO  # Options: DEBUG, INFO, WARNING, ERROR
LOG_FILE_LEVEL=DEBUG
LOG_ARTIFACTS=true
LOG_USE_COLORS=true

# ============================================================================
# OPTIONAL: Service Principal (for Key Vault, Azure AD auth)
# ============================================================================
# AZURE_TENANT_ID=your-tenant-id
# AZURE_CLIENT_ID=your-client-id
# AZURE_CLIENT_SECRET=your-client-secret

# ============================================================================
# OPTIONAL: Key Vault
# ============================================================================
# KEY_VAULT_URI=https://your-keyvault.vault.azure.net/

# ============================================================================
# QUICK CHECKLIST
# ============================================================================
# ☐ Create Azure AI Search service
# ☐ Create Azure OpenAI service and deploy embedding model
# ☐ Create Azure Document Intelligence service
# ☐ Create Azure Storage account
# ☐ Create input blob container (e.g., production-documents-input)
# ☐ Upload documents to input container
# ☐ Fill in all credentials above
# ☐ Run: python -m ingestor.cli --setup-index
# ☐ Run: python -m ingestor.cli

# ============================================================================
# VARIATIONS
# ============================================================================
#
# Cost Optimization:
# - Use gpt-4o-mini for chat (cheaper than gpt-4)
# - Disable image descriptions: AZURE_MEDIA_DESCRIBER=disabled
# - Use text-embedding-3-small with lower dimensions
# - Reduce concurrency to avoid rate limits
#
# Performance Optimization:
# - Increase MAX_WORKERS and concurrency settings
# - Use larger batch sizes
# - Enable integrated vectorization
#
# Hybrid Mode (some local processing):
# - Change INPUT_MODE to local: AZURE_INPUT_MODE=local
# - Keep artifacts in blob for collaboration
#
# ============================================================================
