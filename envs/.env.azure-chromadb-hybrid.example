# ============================================================================
# SCENARIO: Azure Processing with ChromaDB Storage (Hybrid)
# ============================================================================
# USE CASE: Enterprise-grade extraction with local/private vector storage
# COST: $$ (Azure DI + OpenAI only, no Azure Search costs)
# SETUP TIME: 15 minutes
# PROS:
#   - Enterprise OCR quality (Azure Document Intelligence)
#   - High-quality embeddings (Azure OpenAI)
#   - Free local vector storage (ChromaDB)
#   - Data stays local after processing
#   - No recurring search service costs
#   - Can run ChromaDB in-memory or persistent
# CONS:
#   - Less scalable than cloud search
#   - No distributed search capabilities
#   - Requires local disk space for vectors
# ============================================================================

# ============================================================================
# AZURE DOCUMENT INTELLIGENCE (OCR & Layout Analysis)
# ============================================================================
# For PDF/image text extraction with layout preservation
# Pricing: ~$1.50 per 1000 pages (prebuilt-layout model)
# https://azure.microsoft.com/en-us/pricing/details/ai-document-intelligence/

AZURE_DI_ENDPOINT=https://your-document-intelligence.cognitiveservices.azure.com/
AZURE_DI_KEY=your_document_intelligence_key_here

# Model selection
AZURE_DI_MODEL=prebuilt-layout  # prebuilt-layout (best) | prebuilt-read (faster)
AZURE_DI_EXTRACT_TABLES=true

# ============================================================================
# EXTRACTION MODE - LOCAL INPUT
# ============================================================================
EXTRACTION_MODE=azure_di
INPUT_MODE=local  # Read files from local disk (no blob storage needed)

# ============================================================================
# AZURE OPENAI (Embeddings Only)
# ============================================================================
# Using Azure OpenAI for embeddings, but storing in ChromaDB instead of Azure Search
# Pricing: $0.13 per 1M tokens (text-embedding-3-large)

AZURE_OPENAI_ENDPOINT=https://your-openai-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Embedding configuration
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=text-embedding-3-large
AZURE_OPENAI_EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_DIMENSIONS=3072

# Force Azure OpenAI embeddings
EMBEDDINGS_MODE=azure_openai

# ============================================================================
# CHROMADB (Local Vector Store)
# ============================================================================
# Store vectors locally instead of Azure Search - HUGE cost savings!
# Free and open-source, runs locally or as server

# Vector store selection - FORCE ChromaDB
VECTOR_STORE=chromadb

# ChromaDB storage mode
# Options:
#   - 'memory': In-memory only (fast, lost on restart)
#   - 'persistent': Disk-backed (survives restarts)
#   - 'http': Remote ChromaDB server
CHROMADB_MODE=persistent

# Persistent storage location (used when mode=persistent)
CHROMADB_PATH=./chroma_db
CHROMADB_COLLECTION_NAME=ingestor-docs-hybrid

# HTTP/Remote ChromaDB server (used when mode=http)
# CHROMADB_HOST=localhost
# CHROMADB_PORT=8000
# CHROMADB_SSL=false
# CHROMADB_HEADERS={"Authorization": "Bearer token"}  # Optional auth

# ChromaDB settings
CHROMADB_DISTANCE_METRIC=cosine  # cosine | l2 | ip (inner product)
CHROMADB_EMBEDDING_FUNCTION=custom  # Always 'custom' when we provide embeddings

# ============================================================================
# VECTOR SEARCH CONFIGURATION
# ============================================================================
# Must match embedding dimensions from Azure OpenAI
VECTOR_SEARCH_DIMENSIONS=3072

# Search parameters
DEFAULT_TOP_K=10              # Number of results to return
SIMILARITY_THRESHOLD=0.7      # Minimum similarity score (0-1)

# ============================================================================
# CHUNKING CONFIGURATION
# ============================================================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
CHUNKING_STRATEGY=recursive
MIN_CHUNK_SIZE=100
MAX_CHUNK_SIZE=2000

# ============================================================================
# PROCESSING CONFIGURATION
# ============================================================================
BATCH_SIZE=10
EMBEDDING_BATCH_SIZE=100
UPLOAD_BATCH_SIZE=50

# Azure rate limits
MAX_RPM=60
MAX_TOKENS_PER_MINUTE=150000
MAX_RETRIES=3
RETRY_DELAY=1

# ============================================================================
# ARTIFACT MANAGEMENT
# ============================================================================
ARTIFACTS_DIR=./artifacts
KEEP_ARTIFACTS=true
ARTIFACTS_MAX_AGE_DAYS=30
SAVE_EXTRACTED_TEXT=true
SAVE_CHUNKS=true
SAVE_EMBEDDINGS=false  # Usually not needed with ChromaDB

# ============================================================================
# LOGGING & OUTPUT
# ============================================================================
LOG_LEVEL=INFO
LOG_FILE=./logs/ingestor.log
LOG_FORMAT=detailed
VERBOSE=true
NO_COLORS=false
SHOW_PROGRESS=true

# ============================================================================
# OPTIONAL: MEDIA DESCRIPTION with GPT-4o Vision
# ============================================================================
# Describe images/charts from PDFs using Azure OpenAI GPT-4o
ENABLE_MEDIA_DESCRIPTION=true

AZURE_OPENAI_VISION_DEPLOYMENT=gpt-4o
AZURE_OPENAI_VISION_MODEL=gpt-4o
AZURE_OPENAI_VISION_API_VERSION=2024-02-15-preview

VISION_MAX_IMAGES_PER_DOC=50
VISION_MIN_IMAGE_SIZE=100
VISION_DETAIL_LEVEL=high

VISION_DESCRIBE_CHARTS=true
VISION_DESCRIBE_DIAGRAMS=true
VISION_DESCRIBE_PHOTOS=true
VISION_DESCRIBE_TABLES=false

# ============================================================================
# METADATA & VALIDATION
# ============================================================================
DOCUMENT_SOURCE=hybrid_azure_chromadb
ENVIRONMENT=production
PROCESSING_VERSION=1.0

EXTRACT_FILE_METADATA=true
EXTRACT_TEXT_STATS=true

VALIDATE_BEFORE_PROCESSING=true
CHECK_AZURE_QUOTAS=true

# ============================================================================
# EXAMPLE USAGE
# ============================================================================
# 1. Copy this file:
#    cp envs/.env.azure-chromadb-hybrid.example .env
#
# 2. Install dependencies:
#    pip install chromadb azure-ai-documentintelligence azure-identity
#
# 3. Fill in Azure credentials:
#    - Azure Document Intelligence endpoint and key
#    - Azure OpenAI endpoint and API key
#    - (No Azure Search needed!)
#
# 4. Initialize ChromaDB (automatic on first run):
#    python -m ingestor.cli --validate
#
# 5. Process documents:
#    python -m ingestor.cli --pdf ./document.pdf
#    python -m ingestor.cli --glob "docs/**/*.pdf"
#
# 6. Query documents (searches ChromaDB locally):
#    python -m ingestor.cli --query "What is the summary?"
#
# 7. Check ChromaDB collection:
#    python -c "import chromadb; client = chromadb.PersistentClient(path='./chroma_db'); print(client.list_collections())"
#
# ============================================================================
# ADVANTAGES OF THIS HYBRID APPROACH
# ============================================================================
# ✅ Best of both worlds:
#    - Enterprise-grade extraction (Azure DI)
#    - High-quality embeddings (Azure OpenAI)
#    - Free vector storage (ChromaDB)
#
# ✅ Cost savings:
#    - No Azure Search costs (~$250-3000/month)
#    - Only pay for processing (DI + OpenAI API calls)
#    - ~$2-3 per 1000 pages vs $10-15 with full Azure stack
#
# ✅ Data privacy:
#    - Vectors stored locally, not in cloud
#    - Control over data retention
#    - Suitable for sensitive documents
#
# ✅ Flexibility:
#    - Easy to backup (just copy ./chroma_db folder)
#    - Easy to migrate (export/import ChromaDB)
#    - Can switch to http mode for distributed setup
#
# ❌ Trade-offs:
#    - Limited to single machine scale (unless using http mode)
#    - No semantic ranking (Azure Search feature)
#    - Manual backup/replication management
#
# ============================================================================
# CHROMADB STORAGE SIZING
# ============================================================================
# Approximate disk usage per 1000 documents (depends on chunk size):
#   - Metadata: ~50 MB
#   - Vectors (3072 dims): ~500 MB to 2 GB
#   - Total: ~1-2 GB per 1000 documents
#
# For large collections, ensure adequate disk space in CHROMADB_PATH
# ============================================================================

# ============================================================================
# COST ESTIMATION (per 1000 pages)
# ============================================================================
# Azure Document Intelligence: ~$1.50
# Azure OpenAI Embeddings: ~$0.50
# ChromaDB Storage: FREE
# GPT-4o Vision (optional): ~$2-5
# Azure Search: $0 (NOT USED!)
# TOTAL: ~$2-3 per 1000 pages (vs $10-15 with full Azure)
# ============================================================================

# ============================================================================
# CHROMADB DEPLOYMENT OPTIONS
# ============================================================================
#
# OPTION 1: In-Memory (Development/Testing)
# Fast, but data lost on restart
# CHROMADB_MODE=memory
#
# OPTION 2: Persistent (Production Single-Node)
# Data survives restarts, stored on local disk
# CHROMADB_MODE=persistent
# CHROMADB_PATH=./chroma_db
#
# OPTION 3: HTTP Server (Production Distributed)
# Run ChromaDB as separate service, multiple clients can connect
# Terminal 1: docker run -p 8000:8000 chromadb/chroma
# Terminal 2: Set these in .env:
#   CHROMADB_MODE=http
#   CHROMADB_HOST=localhost
#   CHROMADB_PORT=8000
#
# OPTION 4: Docker Compose (Recommended for Production)
# See docker-compose.yml for full setup with ChromaDB server
# ============================================================================

# ============================================================================
# MIGRATION FROM AZURE SEARCH
# ============================================================================
# If migrating from Azure Search to ChromaDB:
#
# 1. Export from Azure Search:
#    python scripts/export_azure_search.py --index ingestor-docs --output vectors.json
#
# 2. Import to ChromaDB:
#    python scripts/import_to_chromadb.py --input vectors.json --collection ingestor-docs-hybrid
#
# 3. Update .env:
#    VECTOR_STORE=chromadb
#    # Comment out Azure Search variables
#
# 4. Validate:
#    python -m ingestor.cli --query "test query"
# ============================================================================

# ============================================================================
# TROUBLESHOOTING
# ============================================================================
# Issue: "Could not import chromadb"
# Solution: pip install chromadb
#
# Issue: "Collection already exists"
# Solution: Use different CHROMADB_COLLECTION_NAME or delete collection:
#   python -c "import chromadb; client = chromadb.PersistentClient(path='./chroma_db'); client.delete_collection('ingestor-docs-hybrid')"
#
# Issue: "Dimension mismatch"
# Solution: Ensure VECTOR_SEARCH_DIMENSIONS matches EMBEDDING_DIMENSIONS
#
# Issue: "Out of disk space"
# Solution: Clean old collections or increase disk space
#   python -m ingestor.cli --clean-artifacts
#
# Issue: "ChromaDB version mismatch"
# Solution: Upgrade to latest: pip install --upgrade chromadb
#
# For more help: python -m ingestor.scenario_validator
# ============================================================================
