# ============================================================================
# SCENARIO: Azure AI Search + Cohere Embeddings (Cloud-Optimized API)
# ============================================================================
#
# DESCRIPTION:
# Cloud-optimized configuration using Azure AI Search for vector storage
# and Cohere's v3 API for embeddings. Cohere provides excellent multilingual
# embeddings with competitive pricing and simple API integration.
#
# USE CASE:
# - Teams wanting cloud embeddings without Azure OpenAI dependency
# - Need multilingual support (100+ languages)
# - Want simple API integration
# - Prefer pay-as-you-go pricing
# - Don't want to manage local embedding infrastructure
#
# COST ESTIMATE (monthly):
# - Azure Search: $250-500 (Standard tier)
# - Cohere embeddings: $50-150 (per 1M tokens, cheaper than Azure OpenAI)
# - Document Intelligence: $10-100 (per 1K pages)
# - Blob Storage: $20-50 (100GB-1TB)
# TOTAL: ~$330-800/month
#
# COMPARISON TO AZURE OPENAI:
# - Cohere: ~$0.10 per 1M tokens
# - Azure OpenAI: ~$0.10 per 1M tokens (text-embedding-ada-002)
# - Similar pricing, but Cohere has better multilingual support
#
# REQUIREMENTS:
# - Azure subscription (Search, Document Intelligence, Storage)
# - Cohere API key (free tier available at cohere.com)
# - pip install cohere
#
# ============================================================================

# ============================================================================
# VECTOR STORE: Azure AI Search
# ============================================================================
VECTOR_STORE_MODE=azure_search
AZURE_SEARCH_SERVICE=your-search-service
AZURE_SEARCH_KEY=your-search-admin-key-here
AZURE_SEARCH_INDEX=cohere-documents

# Alternative: Full endpoint URL
# AZURE_SEARCH_ENDPOINT=https://your-search-service.search.windows.net

# ============================================================================
# EMBEDDINGS: Cohere v3 API
# ============================================================================
EMBEDDINGS_MODE=cohere
COHERE_API_KEY=your-cohere-api-key-here

# Model Selection:
# ----------------------------------------------------------------------------

# OPTION 1: embed-multilingual-v3.0 (RECOMMENDED)
# ------------------------------------------------
COHERE_MODEL_NAME=embed-multilingual-v3.0
# - 1024 dimensions
# - ~512 tokens max
# - 100+ languages
# - Optimized for semantic search
# - Best quality/price ratio

# OPTION 2: embed-english-v3.0 (English Only)
# --------------------------------------------
# COHERE_MODEL_NAME=embed-english-v3.0
# - 1024 dimensions
# - ~512 tokens max
# - English only
# - Slightly better English performance
# - Same price as multilingual

# OPTION 3: embed-multilingual-light-v3.0 (Faster, Cheaper)
# ----------------------------------------------------------
# COHERE_MODEL_NAME=embed-multilingual-light-v3.0
# - 384 dimensions
# - ~512 tokens max
# - 100+ languages
# - Faster inference
# - Lower cost

# OPTION 4: embed-english-light-v3.0 (Fastest)
# ---------------------------------------------
# COHERE_MODEL_NAME=embed-english-light-v3.0
# - 384 dimensions
# - ~512 tokens max
# - English only
# - Fastest processing
# - Lowest cost

# Cohere-Specific Configuration:
# ----------------------------------------------------------------------------
COHERE_INPUT_TYPE=search_document  # For indexing documents

# Alternative input types:
# - search_query: For search queries (you'll use this when searching)
# - classification: For classification tasks
# - clustering: For clustering tasks

COHERE_TRUNCATE=END  # Truncate from end if text exceeds limit

# Alternative truncate options:
# - NONE: Return error if text too long (strict mode)
# - START: Truncate from start
# - END: Truncate from end (recommended)

# IMPORTANT: Disable integrated vectorization (we're using Cohere)
AZURE_USE_INTEGRATED_VECTORIZATION=false

# ============================================================================
# DOCUMENT INTELLIGENCE: Azure DI
# ============================================================================
AZURE_DOC_INT_ENDPOINT=https://your-docint.cognitiveservices.azure.com/
AZURE_DOC_INT_KEY=your-document-intelligence-key-here
AZURE_DI_MAX_CONCURRENCY=3

# Office Document Processing:
AZURE_OFFICE_EXTRACTOR_MODE=hybrid
AZURE_OFFICE_OFFLINE_FALLBACK=true

# ============================================================================
# STORAGE: Azure Blob Storage
# ============================================================================
AZURE_STORAGE_ACCOUNT=your-storage-account
AZURE_STORAGE_ACCOUNT_KEY=your-storage-account-key-here

# Alternative: Connection string
# AZURE_CONNECTION_STRING=DefaultEndpointsProtocol=https;AccountName=...

# ============================================================================
# INPUT: Azure Blob Storage
# ============================================================================
AZURE_INPUT_MODE=blob
AZURE_STORAGE_CONTAINER=cohere-documents

# Alternative: Local input
# AZURE_INPUT_MODE=local
# AZURE_LOCAL_GLOB=data/**/*.pdf

# ============================================================================
# ARTIFACTS: Azure Blob Storage
# ============================================================================
AZURE_ARTIFACTS_MODE=blob
AZURE_BLOB_CONTAINER_PREFIX=cohere
AZURE_BLOB_CONTAINER_OUT_PAGES=pages
AZURE_BLOB_CONTAINER_OUT_CHUNKS=chunks
AZURE_BLOB_CONTAINER_OUT_IMAGES=images

# Alternative: Local artifacts
# AZURE_ARTIFACTS_DIR=./artifacts

# ============================================================================
# PROCESSING OPTIONS
# ============================================================================

# Media Description:
# ----------------------------------------------------------------------------
# Option 1: Disabled (cost optimization)
AZURE_MEDIA_DESCRIBER=disabled

# Option 2: GPT-4 via Azure OpenAI (requires Azure OpenAI)
# AZURE_MEDIA_DESCRIBER=gpt4o
# AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
# AZURE_OPENAI_KEY=your-openai-key-here
# AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini

# Note: Cohere doesn't provide vision/multimodal models yet
#       Use Azure OpenAI or disable for image descriptions

# Table Processing:
# ----------------------------------------------------------------------------
AZURE_TABLE_RENDER=markdown
AZURE_TABLE_SUMMARIES=false

# ============================================================================
# CHUNKING CONFIGURATION (Dynamic Adjustment)
# ============================================================================
# Cohere models have ~512 token context limit
# Safe limit = 512 * (1 - 0.15 - 0.10) = 384 tokens

CHUNKING_MAX_TOKENS=384  # Safe for Cohere's 512-token limit
CHUNKING_MAX_CHARS=2000
CHUNKING_OVERLAP_PERCENT=10

# Note: Cohere's truncate=END handles overflow, but dynamic chunking
#       prevents information loss by keeping chunks within limits

# ============================================================================
# PERFORMANCE TUNING
# ============================================================================
AZURE_CHUNKING_MAX_WORKERS=4
AZURE_CHUNKING_MAX_IMAGE_CONCURRENCY=8
AZURE_CHUNKING_MAX_BATCH_UPLOAD_CONCURRENCY=5
AZURE_EMBED_BATCH_SIZE=96  # Cohere supports batch processing

# ============================================================================
# DUMMY AZURE OPENAI CONFIG (Only Used if Media Describer Enabled)
# ============================================================================
AZURE_OPENAI_ENDPOINT=https://dummy.openai.azure.com/
AZURE_OPENAI_KEY=dummy-key-not-used-for-embeddings
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=dummy-not-used
AZURE_OPENAI_EMBEDDING_MODEL=dummy-not-used

# ============================================================================
# LOGGING
# ============================================================================
LOG_LEVEL=INFO
LOG_FILE_LEVEL=DEBUG
LOG_ARTIFACTS=true
LOG_USE_COLORS=true

# ============================================================================
# COHERE API PRICING & LIMITS
# ============================================================================
#
# PRICING (as of 2024):
# ---------------------
# embed-multilingual-v3.0: ~$0.10 per 1M tokens
# embed-english-v3.0: ~$0.10 per 1M tokens
# embed-multilingual-light-v3.0: ~$0.02 per 1M tokens
# embed-english-light-v3.0: ~$0.02 per 1M tokens
#
# RATE LIMITS (Production Tier):
# -------------------------------
# - 10,000 requests per minute
# - 100 million tokens per minute
# - Batch size up to 96 texts per request
#
# FREE TIER:
# ----------
# - 100 API calls per minute
# - 1,000 calls per month free
# - Good for testing and small projects
#
# ============================================================================
# COHERE VS ALTERNATIVES
# ============================================================================
#
# COHERE VS AZURE OPENAI:
# -----------------------
# Advantages:
#   ✅ Better multilingual support (100+ languages)
#   ✅ No Azure OpenAI quota/region limitations
#   ✅ Simple API, easy to use
#   ✅ Competitive pricing
#   ✅ Free tier available
#
# Disadvantages:
#   ❌ No integrated vectorization with Azure Search
#   ❌ No vision/multimodal support
#   ❌ Smaller community/ecosystem
#
# COHERE VS HUGGING FACE (LOCAL):
# --------------------------------
# Advantages:
#   ✅ No local infrastructure needed
#   ✅ No GPU required
#   ✅ Consistent performance
#   ✅ Automatic scaling
#   ✅ Pay-as-you-go
#
# Disadvantages:
#   ❌ API costs (vs free local)
#   ❌ Internet required
#   ❌ Data leaves your infrastructure
#   ❌ Rate limits
#
# ============================================================================
# WHEN TO USE COHERE
# ============================================================================
#
# ✅ BEST FOR:
# - Need cloud embeddings without Azure OpenAI
# - Multilingual content (100+ languages)
# - Don't want to manage local GPU infrastructure
# - Want simple API integration
# - Medium to high volume (1K-1M pages/month)
# - Need consistent, predictable performance
#
# ❌ NOT IDEAL FOR:
# - Need integrated vectorization (use Azure OpenAI)
# - Very high volume (>10M pages/month) - local cheaper
# - Air-gapped/offline requirements (use Hugging Face)
# - Need vision/multimodal embeddings
# - Very low volume (<100 pages/month) - setup overhead
#
# ✅ CONSIDER COHERE IF:
# - You like OpenAI's API but want better multilingual
# - You're in a region without Azure OpenAI quota
# - You want to diversify embedding providers
# - You need faster multilingual inference than local CPU
#
# ============================================================================
# SETUP INSTRUCTIONS
# ============================================================================
#
# 1. Get Cohere API Key:
#    - Sign up at https://cohere.com/
#    - Navigate to Dashboard → API Keys
#    - Create production API key
#    - Copy key to COHERE_API_KEY above
#
# 2. Install Cohere SDK:
#    pip install cohere
#
# 3. Create Azure Resources:
#    - Azure AI Search service
#    - Azure Document Intelligence
#    - Azure Storage account
#    - Create input blob container
#
# 4. Configure Environment:
#    - Fill in Azure credentials above
#    - Set Cohere API key
#    - Choose Cohere model
#
# 5. Test Configuration:
#    python -m ingestor.cli --setup-index
#    python -m ingestor.cli
#
# ============================================================================
# COHERE BEST PRACTICES
# ============================================================================
#
# 1. Model Selection:
#    - Multilingual content: embed-multilingual-v3.0
#    - English only: embed-english-v3.0
#    - Cost sensitive: use -light variants
#
# 2. Input Type:
#    - Indexing: COHERE_INPUT_TYPE=search_document
#    - Querying: Use search_query in your search code
#    - This improves retrieval quality
#
# 3. Truncation:
#    - Use COHERE_TRUNCATE=END (recommended)
#    - But better: use dynamic chunking to avoid truncation
#    - CHUNKING_MAX_TOKENS=384 prevents data loss
#
# 4. Batch Processing:
#    - Cohere supports up to 96 texts per batch
#    - Use AZURE_EMBED_BATCH_SIZE=96 for best performance
#    - Reduces API calls and improves throughput
#
# 5. Rate Limiting:
#    - Free tier: 100 calls/min
#    - Production: 10,000 calls/min
#    - Adjust concurrency if you hit limits
#
# 6. Error Handling:
#    - Cohere automatically retries transient errors
#    - Configure AZURE_OPENAI_MAX_RETRIES (reused for Cohere)
#    - Monitor API usage in Cohere dashboard
#
# ============================================================================
# MULTILINGUAL SUPPORT
# ============================================================================
#
# Cohere's multilingual models support 100+ languages:
#
# Major Languages:
# - European: English, Spanish, French, German, Italian, Portuguese, etc.
# - Asian: Chinese, Japanese, Korean, Hindi, Bengali, Vietnamese, etc.
# - Middle Eastern: Arabic, Hebrew, Persian, Turkish
# - African: Swahili, Yoruba, Zulu
# - And many more...
#
# Cross-Lingual Search:
# - Query in one language, find results in another
# - Example: English query → Spanish/French/Chinese results
# - embed-multilingual-v3.0 excels at this
#
# Performance:
# - Similar quality to multilingual-e5-large (Hugging Face)
# - Better than Azure OpenAI's ada-002 for non-English
# - Optimized for semantic search tasks
#
# ============================================================================
# MONITORING & DEBUGGING
# ============================================================================
#
# Monitor Usage:
# - Check Cohere Dashboard: https://dashboard.cohere.com/
# - View API calls, tokens, costs
# - Set up usage alerts
#
# Debug Issues:
# - Enable DEBUG logging: LOG_LEVEL=DEBUG
# - Check for truncation warnings
# - Verify token counts in artifacts/chunks/
# - Test with small corpus first
#
# Performance Metrics:
# - API latency: ~100-300ms per batch
# - Throughput: ~1,000-5,000 docs/hour (depends on doc size)
# - Cost: ~$0.10 per 1M tokens processed
#
# ============================================================================
