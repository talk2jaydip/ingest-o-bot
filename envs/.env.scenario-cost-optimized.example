# ============================================================================
# SCENARIO: Cost-Optimized Azure (Hybrid Local Embeddings)
# ============================================================================
#
# DESCRIPTION:
# Hybrid configuration that uses Azure AI Search for vector storage but
# local Hugging Face embeddings to eliminate embedding API costs. Keeps
# Azure Document Intelligence for quality PDF processing.
#
# USE CASE:
# - Cost-conscious production deployments
# - High-volume document processing (millions of pages)
# - Need Azure Search but want to reduce OpenAI costs
# - Have GPU available for fast local embeddings
#
# COST ESTIMATE (monthly):
# - Azure Search: $250-500 (Standard tier)
# - Azure OpenAI: $0-50 (optional, only for image descriptions)
# - Document Intelligence: $10-100 (per 1K pages)
# - Blob Storage: $20-50 (100GB-1TB)
# - Local embeddings: $0 (free!)
# TOTAL: ~$280-700/month (vs $380-950 for full Azure)
# SAVINGS: $100-250/month (26% cost reduction)
#
# For high-volume (1M pages/month):
# - Traditional Azure OpenAI embeddings: $1,000+ in embedding costs
# - This configuration: $0 in embedding costs
# SAVINGS: $1,000+/month
#
# REQUIREMENTS:
# - Azure subscription (Azure Search, Document Intelligence, Storage)
# - Local compute with CPU or GPU for embeddings
# - pip install sentence-transformers torch
#
# ============================================================================

# ============================================================================
# VECTOR STORE: Azure AI Search
# ============================================================================
VECTOR_STORE_MODE=azure_search
AZURE_SEARCH_SERVICE=your-search-service
AZURE_SEARCH_KEY=your-search-admin-key-here
AZURE_SEARCH_INDEX=cost-optimized-documents

# ============================================================================
# EMBEDDINGS: Hugging Face (Local, Zero Cost)
# ============================================================================
EMBEDDINGS_MODE=huggingface

# Recommended Model: Multilingual E5 Large (best quality/cost ratio)
HUGGINGFACE_MODEL_NAME=intfloat/multilingual-e5-large
# - 1024 dimensions, 512 max tokens
# - ~2.2GB model size
# - 100+ languages
# - State-of-the-art quality
# - FREE (no API costs)

# Alternative: BGE Large English (English-only, slightly smaller)
# HUGGINGFACE_MODEL_NAME=BAAI/bge-large-en-v1.5
# - 1024 dimensions, 512 max tokens
# - ~1.3GB model size

# Alternative: All-MPNet-Base-v2 (balanced, smaller)
# HUGGINGFACE_MODEL_NAME=sentence-transformers/all-mpnet-base-v2
# - 768 dimensions, 384 max tokens
# - ~420MB model size

# Device Configuration:
# ----------------------------------------------------------------------------
# RECOMMENDED: Use GPU for 5-10x speedup
HUGGINGFACE_DEVICE=cuda  # NVIDIA GPU
HUGGINGFACE_BATCH_SIZE=64  # Larger batch for GPU

# CPU fallback:
# HUGGINGFACE_DEVICE=cpu
# HUGGINGFACE_BATCH_SIZE=32

# Apple Silicon:
# HUGGINGFACE_DEVICE=mps
# HUGGINGFACE_BATCH_SIZE=48

HUGGINGFACE_NORMALIZE=true

# IMPORTANT: Disable integrated vectorization (we're doing client-side)
AZURE_USE_INTEGRATED_VECTORIZATION=false

# ============================================================================
# DOCUMENT INTELLIGENCE: Azure DI (Quality Extraction)
# ============================================================================
AZURE_DOC_INT_ENDPOINT=https://your-docint.cognitiveservices.azure.com/
AZURE_DOC_INT_KEY=your-document-intelligence-key-here
AZURE_DI_MAX_CONCURRENCY=3

# Office Document Processing:
AZURE_OFFICE_EXTRACTOR_MODE=hybrid
AZURE_OFFICE_OFFLINE_FALLBACK=true

# ============================================================================
# STORAGE: Azure Blob Storage
# ============================================================================
AZURE_STORAGE_ACCOUNT=your-storage-account
AZURE_STORAGE_ACCOUNT_KEY=your-storage-account-key-here

# ============================================================================
# INPUT: Azure Blob Storage
# ============================================================================
AZURE_INPUT_MODE=blob
AZURE_STORAGE_CONTAINER=cost-optimized

# Alternative: Local input to save on blob costs
# AZURE_INPUT_MODE=local
# AZURE_LOCAL_GLOB=data/**/*.pdf

# ============================================================================
# ARTIFACTS: Azure Blob Storage
# ============================================================================
AZURE_ARTIFACTS_MODE=blob
AZURE_BLOB_CONTAINER_PREFIX=cost-optimized
AZURE_BLOB_CONTAINER_OUT_PAGES=pages
AZURE_BLOB_CONTAINER_OUT_CHUNKS=chunks
AZURE_BLOB_CONTAINER_OUT_IMAGES=images

# Alternative: Local artifacts to save on blob storage costs
# AZURE_ARTIFACTS_DIR=./artifacts

# ============================================================================
# PROCESSING OPTIONS (Cost Minimization)
# ============================================================================

# Media Description: COST CONSIDERATION
# ----------------------------------------------------------------------------
# Option 1: Disable (zero cost, recommended for cost optimization)
AZURE_MEDIA_DESCRIBER=disabled

# Option 2: Use GPT-4o-mini (low cost, ~$0.15-0.60 per 1K images)
# AZURE_MEDIA_DESCRIBER=gpt4o
# AZURE_OPENAI_ENDPOINT=https://your-openai.openai.azure.com/
# AZURE_OPENAI_KEY=your-openai-key-here
# AZURE_OPENAI_CHAT_DEPLOYMENT=gpt-4o-mini

# Table Processing:
# ----------------------------------------------------------------------------
AZURE_TABLE_RENDER=markdown  # Lightweight format
AZURE_TABLE_SUMMARIES=false  # Disable (would require LLM calls)

# Citations:
# ----------------------------------------------------------------------------
AZURE_GENERATE_PAGE_PDFS=false  # Disable to save storage costs

# ============================================================================
# CHUNKING CONFIGURATION (Dynamic Adjustment)
# ============================================================================
# For multilingual-e5-large (max_seq_length = 512):
#   Safe limit = 512 * (1 - 0.15 - 0.10) = 384 tokens
CHUNKING_MAX_TOKENS=384  # Safe for 512-token model
CHUNKING_MAX_CHARS=2000
CHUNKING_OVERLAP_PERCENT=10

# ============================================================================
# PERFORMANCE TUNING (GPU Optimized)
# ============================================================================
AZURE_CHUNKING_MAX_WORKERS=4
AZURE_EMBED_BATCH_SIZE=128  # Large batch for GPU
AZURE_UPLOAD_BATCH_SIZE=1000

# ============================================================================
# DUMMY AZURE OPENAI CONFIG (Not Used for Embeddings)
# ============================================================================
# These are only needed if you enable gpt4o media describer above
AZURE_OPENAI_ENDPOINT=https://dummy.openai.azure.com/
AZURE_OPENAI_KEY=dummy-key-not-used-for-embeddings
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=dummy-not-used
AZURE_OPENAI_EMBEDDING_MODEL=dummy-not-used

# ============================================================================
# LOGGING
# ============================================================================
LOG_LEVEL=INFO
LOG_FILE_LEVEL=DEBUG
LOG_ARTIFACTS=true
LOG_USE_COLORS=true

# ============================================================================
# COST BREAKDOWN & COMPARISON
# ============================================================================
#
# TRADITIONAL AZURE OPENAI EMBEDDINGS:
# -------------------------------------
# - Azure Search: $250-500/month
# - Azure OpenAI embeddings: $0.10 per 1M tokens
#   * 1M pages = ~500M tokens = $50/month (light docs)
#   * 1M pages = ~2B tokens = $200/month (heavy docs)
# - Azure OpenAI GPT-4 descriptions: $50-100/month
# - Document Intelligence: $10-100/month
# - Blob Storage: $20-50/month
# TOTAL: $380-950/month (typical)
#        $500-1,500/month (high volume)
#
# THIS CONFIGURATION (LOCAL EMBEDDINGS):
# --------------------------------------
# - Azure Search: $250-500/month
# - Local Hugging Face embeddings: $0/month
# - Azure OpenAI GPT-4 descriptions: $0 (disabled) or $20-50 (enabled)
# - Document Intelligence: $10-100/month
# - Blob Storage: $20-50/month
# TOTAL: $280-700/month
#
# SAVINGS: $100-800/month (10-50% cost reduction)
# High volume savings: $1,000+/month
#
# ============================================================================
# PERFORMANCE NOTES
# ============================================================================
#
# GPU Acceleration (RECOMMENDED):
# - NVIDIA GPU: 5-10x faster than CPU
# - Apple M1/M2/M3: 3-5x faster than CPU
# - 100-page PDF processing time: 1-2 minutes (GPU) vs 8-12 minutes (CPU)
#
# Cost of GPU:
# - AWS g4dn.xlarge: ~$0.50/hour = ~$360/month (24/7)
# - Still cheaper than Azure OpenAI embeddings at scale!
# - Or use existing GPU infrastructure
#
# Model Download:
# - First run downloads ~2.2GB model from Hugging Face
# - Cached locally for future runs (~/.cache/huggingface/)
# - No internet required after initial download
#
# ============================================================================
# WHEN TO USE THIS CONFIGURATION
# ============================================================================
#
# ✅ BEST FOR:
# - Processing 100K+ pages per month
# - High-volume production deployments
# - Cost-conscious organizations
# - Have GPU available (cloud or on-prem)
# - Need Azure Search but want to reduce costs
#
# ❌ NOT IDEAL FOR:
# - Very low volume (<1K pages/month) - setup overhead not worth it
# - No GPU available and need fast processing
# - Need integrated vectorization with Azure Search
# - Want simplest possible setup
#
# ============================================================================
